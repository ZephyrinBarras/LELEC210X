{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import Feature_vector_DS\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from classification.utils.utils import accuracy\n",
    "import numpy as np\n",
    "import os, threading\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "### TO RUN\n",
    "PATH = \"data/feature_freq/\"  # where to save the features matrices\n",
    "model_dir = \"data/models/\"  # where to save the models\n",
    "os.makedirs(PATH, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0, fs=11111)\n",
    "train_pct = 0.7\n",
    "featveclen = len(myds[\"fire\", 0])  # number of items in a feature vector\n",
    "nitems = len(myds)  # number of sounds in the dataset\n",
    "naudio = dataset.naudio  # number of audio files in each class\n",
    "nclass = dataset.nclass  # number of classes\n",
    "nlearn = round(naudio * train_pct)  # number of sounds among naudio for training\n",
    "\n",
    "data_aug_factor = 1\n",
    "class_ids_aug = np.repeat(classnames, naudio * data_aug_factor)\n",
    "\n",
    "\"Compute the matrixed dataset, this takes some seconds, but you can then reload it by commenting this loop and decommenting the np.load below\"\n",
    "X = np.zeros((data_aug_factor * nclass * naudio, featveclen))\n",
    "for s in range(data_aug_factor):\n",
    "    for class_idx, classname in enumerate(classnames):\n",
    "        for idx in range(naudio):\n",
    "            featvec = myds[classname, idx]\n",
    "            X[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "np.save(PATH + \"feature_matrix_2D.npy\", X)\n",
    "\n",
    "class_ids_aug = np.repeat(classnames, naudio * data_aug_factor)\n",
    "y = class_ids_aug.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonction pour thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m X_learn_normalised \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(X_learn_normalised)\n\u001b[1;32m     30\u001b[0m X_val_normalised \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_val_normalised)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpca_vite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(X_learn_normalised[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_val_normalised[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERrOR \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_learn_normalised[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_val_normalised[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "\n",
    "model_knn = RandomForestClassifier(150)\n",
    "\n",
    "t1 = time()\n",
    "pca = PCA(n_components=8,whiten=True)\n",
    "myds_th = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=5000, shift_pct=0.0,fs=11111)\n",
    "featveclen=len(myds_th['fire', 0])\n",
    "X = np.zeros((data_aug_factor * nclass * naudio, featveclen))\n",
    "for s in range(data_aug_factor):\n",
    "    for class_idx, classname in enumerate(classnames):\n",
    "        for idx in range(naudio):\n",
    "            featvec = myds_th[classname, idx]\n",
    "            X[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "np.save(PATH +str(111111)+ \"feature_matrix_2D.npy\", X)\n",
    "\n",
    "#classification\n",
    "acc = []\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)  # random_state=1\n",
    "\n",
    "mean = np.mean(X_train, axis=0)\n",
    "X_train_mean=X_train-mean\n",
    "X_learn_normalised = X_train_mean/ np.linalg.norm(X_train_mean, axis=1, keepdims=True)\n",
    "\n",
    "mean = np.mean(X_test, axis=0)\n",
    "X_val_mean=X_test-mean\n",
    "X_val_normalised = X_val_mean/ np.linalg.norm(X_val_mean, axis=1, keepdims=True)\n",
    "\n",
    "    \n",
    "X_learn_normalised = pca.fit_transform(X_learn_normalised)\n",
    "X_val_normalised = pca.transform(X_val_normalised)\n",
    "pickle.dump(pca, open(\"./pca_vite\", 'wb'))\n",
    "\n",
    "if(len(X_learn_normalised[0])!=len(X_val_normalised[0])):\n",
    "    raise(f\"ERrOR {len(X_learn_normalised[0])}, {len(X_val_normalised[0])}\")\n",
    "\n",
    "model_knn.fit(X_learn_normalised, y_train)\n",
    "prediction_knn = model_knn.predict(X_val_normalised)\n",
    "print(accuracy(prediction_knn, y_test))\n",
    "pickle.dump(model_knn, open(\"./model_vite\", 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lelec210x-AEOhaAdd-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
